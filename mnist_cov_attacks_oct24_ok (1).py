# -*- coding: utf-8 -*-
"""Mnist_COV_ATTACKS_OCT24_ok.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c4SMwREdqCe4kbEaHYEb2Xh9z9kDacMC
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %pip install celluloid
# %pip install torch torchvision
# %pip install torchattacks

import sys
sys.path.append('/content/drive/MyDrive/local_lipschitz-master')
import network_bound
import my_config

import torch
import torchvision
import numpy as np
from torchvision import datasets, transforms

import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchattacks

from celluloid import Camera
device = 'cuda' if torch.cuda.is_available() else 'cpu'

from sklearn import datasets
from sklearn.manifold import TSNE
import time

epsi=0.01
batch_size_train = 2048
batch_size_test = 1
learning_rate = 0.01
momentum = 0.3
log_interval = 10

train_loader = torch.utils.data.DataLoader(
  torchvision.datasets.MNIST(root='./files/', train=True, download=True,
                             transform=torchvision.transforms.Compose([
                               torchvision.transforms.ToTensor(),
                               torchvision.transforms.Normalize(
                                 (0.1307,), (0.3081,))
                             ])),
  batch_size=batch_size_train, shuffle=True)
test_loader = torch.utils.data.DataLoader(
  torchvision.datasets.MNIST(root='./files/''/files/', train=False, download=True,
                             transform=torchvision.transforms.Compose([
                               torchvision.transforms.ToTensor(),
                               torchvision.transforms.Normalize(
                                 (0.1307,), (0.3081,))
                             ])),
  batch_size=batch_size_test, shuffle=True)

examples = enumerate(train_loader)
batch_idx, (example_data, example_targets) = next(examples)
example_data.to(device)
example_targets.to(device)

print(example_data.shape)
#pause = input()

import matplotlib.pyplot as plt

fig = plt.figure()
for i in range(6):
  plt.subplot(2,3,i+1)
  plt.tight_layout()
  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')
  plt.title("Ground Truth: {}".format(example_targets[i]))
  plt.xticks([])
  plt.yticks([])

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1)
        self.dropout1 = nn.Dropout(0.25)
        self.dropout2 = nn.Dropout(0.5)
        self.fc1 = nn.Linear(9216, 128)
        self.fc2 = nn.Linear(128,22 )
        self.fc3 = nn.Linear(22, 10)
        self.pool = nn.MaxPool2d(2)
        self.relu = nn.ReLU(inplace=False)
        self.flatten = nn.Flatten()


    def forward(self, x):
        x = self.relu(self.conv1(x))
        #x = F.relu(x)
        x = self.relu(self.conv2(x))
        #x = F.relu(x)
        x = self.pool(x)
        #x = self.dropout1(x)
        x = torch.flatten(x, 1)
        x = self.relu(self.fc1(x))
        x = F.relu(x)
        #x = self.dropout2(x)
        x = self.fc2(x)
        y=x
        x = F.relu(x)
        x = self.fc3(x)
        output = F.log_softmax(x, dim=1)
        return output

#network = torch.load('/content/drive/MyDrive/MNIST_False3.pth', weights_only=False,map_location=torch.device('cpu'))
network = torch.load('/content/drive/MyDrive/MNIST_True2.pth', weights_only=False,map_location=torch.device('cpu'))

#----------- GPU ---------------------------------------------------
#network = torch.load('/content/drive/MyDrive/MNIST_False3.pth', weights_only=False)
#network = torch.load('/content/drive/MyDrive/modelo_True_96.pth', weights_only=False)

network.eval()

def testa( model, device, test_loader, epsilon, attack ):
    #print('device= ',device)
    # Accuracy counter
    correct = 0
    adv_examples = []
    i=0
    # Loop over all examples in test set
    for data, target in test_loader:
        if i%1000==0:
          print('i= ',i)
        if i==1000:
          print('i= ',i)
          #break
        i+=1

        # Send the data and label to the device
        data, target = data.to(device), target.to(device)
        # Forward pass the data through the model
        output = model(data).to(device)
        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability

        # If the initial prediction is wrong, don't bother attacking, just move on
        if init_pred.item() != target.item():
            continue

        match attack:
          case 'fgsm':
            atk = torchattacks.FGSM(model, eps=8/255)
          case 'jsma':
            atk = torchattacks.JSMA(model, theta=1.0, gamma=0.1)
          case 'cw':
            atk= torchattacks.CW(model, c=1, kappa=40, steps=50, lr=0.01) #kappa ca de 0 a 40 en el paper a mayor valor mas fuerte
          case 'df':
            atk = torchattacks.DeepFool(model, steps=50, overshoot=0.02)
          case 'gaussian':
            atk = torchattacks.GN(model, std=epsilon)
          case 'pgd':
            atk = torchattacks.PGD(model, eps=8/255, alpha=1/255, steps=10, random_start=True)
          case 'sparse':
            atk = torchattacks.SparseFool(model, steps=10, lam=3, overshoot=0.02) #lambda >= 1 va de 1,2,3,..,6 en el paper
          case 'auto':
            atk =torchattacks.AutoAttack(model, norm='Linf', eps=8/255, version='standard', n_classes=10, seed=None, verbose=False)

        atk.set_normalization_used(mean=[0.1307,], std=[0.3081,]) # If inputs were normalized, then
        perturbed_data = atk(data, target)
        # Re-classify the perturbed image
        output = model(perturbed_data)

        # Check for success
        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability
        if final_pred.item() == target.item():
            correct += 1
            # Special case for saving 0 epsilon examples
            if epsilon == 0 and len(adv_examples) < 5:
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )
        else:
            # Save some adv examples for visualization later
            if len(adv_examples) < 5:
                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()
                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )

    # Calculate final accuracy for this epsilon
    final_acc = correct/float(len(test_loader))
    print(f"Epsilon: {epsilon}\tTest Accuracy = {correct} / {len(test_loader)} = {final_acc}")

    # Return the accuracy and an adversarial example
    return final_acc, adv_examples

attack='gaussian'
epsilons = [0.3]
accuracies = []
examples = []

# Run test for each epsilon
for eps in epsilons:
    acc, ex = testa(network, device, test_loader, eps,attack)
    accuracies.append(acc)
    examples.append(ex)

# Plot several examples of adversarial samples at each epsilon
cnt = 0
plt.figure(figsize=(8,10))
for i in range(len(epsilons)):
    for j in range(len(examples[i])):
        cnt += 1
        plt.subplot(len(epsilons),len(examples[0]),cnt)
        plt.xticks([], [])
        plt.yticks([], [])
        if j == 0:
            plt.ylabel(f"Theta: {epsilons[i]}", fontsize=14)
        orig,adv,ex = examples[i][j]
        plt.title(f"{orig} -> {adv}")
        plt.imshow(ex, cmap="gray")
plt.tight_layout()
plt.show()

c=0
for eps in epsilons:
    print(accuracies[c])
    c+=1



from IPython.display import Audio, display
display(Audio("/content/drive/MyDrive/sound.ogg", autoplay=True))